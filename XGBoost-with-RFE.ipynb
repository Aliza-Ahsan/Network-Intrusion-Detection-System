{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nimport itertools\nfrom tabulate import tabulate\nfrom sklearn.model_selection import GridSearchCV\nimport itertools\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import accuracy_score, classification_report, log_loss\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:16.225584Z","iopub.execute_input":"2024-11-08T07:16:16.226111Z","iopub.status.idle":"2024-11-08T07:16:16.235866Z","shell.execute_reply.started":"2024-11-08T07:16:16.226058Z","shell.execute_reply":"2024-11-08T07:16:16.234561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the training and test datasets\ntrain_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\ntest_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\ncol_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:16.238298Z","iopub.execute_input":"2024-11-08T07:16:16.239189Z","iopub.status.idle":"2024-11-08T07:16:16.254933Z","shell.execute_reply.started":"2024-11-08T07:16:16.239132Z","shell.execute_reply":"2024-11-08T07:16:16.253774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(train_url, header=None, names=col_names)\ntest = pd.read_csv(test_url, header=None, names=col_names)\nprint('Dimensions of the Training set:',train.shape)\nprint('Dimensions of the Test set:',test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:16.256357Z","iopub.execute_input":"2024-11-08T07:16:16.256832Z","iopub.status.idle":"2024-11-08T07:16:18.431251Z","shell.execute_reply.started":"2024-11-08T07:16:16.256779Z","shell.execute_reply":"2024-11-08T07:16:18.430032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Label adjustment\ntrain[\"label\"] = train[\"label\"].apply(lambda x: \"normal\" if x == \"normal\" else \"anomalous\")\ntest[\"label\"] = test[\"label\"].apply(lambda x: \"normal\" if x == \"normal\" else \"anomalous\")\n# Checking the distribution after the change\nprint(train[\"label\"].value_counts())\nprint()\nprint(test[\"label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.432454Z","iopub.execute_input":"2024-11-08T07:16:18.432899Z","iopub.status.idle":"2024-11-08T07:16:18.484646Z","shell.execute_reply.started":"2024-11-08T07:16:18.432850Z","shell.execute_reply":"2024-11-08T07:16:18.483504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of duplicate rows: {train.duplicated().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.488457Z","iopub.execute_input":"2024-11-08T07:16:18.489588Z","iopub.status.idle":"2024-11-08T07:16:18.618361Z","shell.execute_reply.started":"2024-11-08T07:16:18.489532Z","shell.execute_reply":"2024-11-08T07:16:18.616759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of duplicate rows: {test.duplicated().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.619912Z","iopub.execute_input":"2024-11-08T07:16:18.620310Z","iopub.status.idle":"2024-11-08T07:16:18.655803Z","shell.execute_reply.started":"2024-11-08T07:16:18.620270Z","shell.execute_reply":"2024-11-08T07:16:18.654540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Removing duplicate rows\ntest.drop_duplicates(inplace=True)\n\n# Check the shape of the dataset after removing duplicates\nprint(f\"New shape of the dataset: {test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.656933Z","iopub.execute_input":"2024-11-08T07:16:18.657270Z","iopub.status.idle":"2024-11-08T07:16:18.693072Z","shell.execute_reply.started":"2024-11-08T07:16:18.657235Z","shell.execute_reply":"2024-11-08T07:16:18.691328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Removing duplicate rows\ntrain.drop_duplicates(inplace=True)\n\n# Check the shape of the dataset after removing duplicates\nprint(f\"New shape of the dataset: {train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.694600Z","iopub.execute_input":"2024-11-08T07:16:18.694986Z","iopub.status.idle":"2024-11-08T07:16:18.839406Z","shell.execute_reply.started":"2024-11-08T07:16:18.694947Z","shell.execute_reply":"2024-11-08T07:16:18.838342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\ndef check_constant_columns(test):\n    constant_columns = [col for col in test.columns if test[col].nunique() == 1]\n    return constant_columns\n\n# Example usage\nconstant_cols = check_constant_columns(test)\nif constant_cols:\n    print(f\"Columns with the same value across all rows: {constant_cols}\")\nelse:\n    print(\"No columns have the same value across all rows.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.840969Z","iopub.execute_input":"2024-11-08T07:16:18.841930Z","iopub.status.idle":"2024-11-08T07:16:18.870412Z","shell.execute_reply.started":"2024-11-08T07:16:18.841880Z","shell.execute_reply":"2024-11-08T07:16:18.868441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dropping a column because every value is 0 \ntrain.drop(['num_outbound_cmds'], axis=1, inplace=True)\ntest.drop(['num_outbound_cmds'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.872039Z","iopub.execute_input":"2024-11-08T07:16:18.872435Z","iopub.status.idle":"2024-11-08T07:16:18.897959Z","shell.execute_reply.started":"2024-11-08T07:16:18.872395Z","shell.execute_reply":"2024-11-08T07:16:18.896384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply LabelEncoding\ndef LabelEncoding(df):\n    for col in df.columns:\n        if df[col].dtype == 'object':\n            label_encoder = LabelEncoder()\n            df[col] = label_encoder.fit_transform(df[col])\n\nLabelEncoding(train)\nLabelEncoding(test)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:18.899784Z","iopub.execute_input":"2024-11-08T07:16:18.900280Z","iopub.status.idle":"2024-11-08T07:16:19.035330Z","shell.execute_reply.started":"2024-11-08T07:16:18.900225Z","shell.execute_reply":"2024-11-08T07:16:19.034279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = train.drop([\"label\"], axis=1)\ny_train = train[\"label\"]\nX_test = test.drop([\"label\"], axis=1)\ny_test = test[\"label\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:19.036799Z","iopub.execute_input":"2024-11-08T07:16:19.037269Z","iopub.status.idle":"2024-11-08T07:16:19.055856Z","shell.execute_reply.started":"2024-11-08T07:16:19.037213Z","shell.execute_reply":"2024-11-08T07:16:19.054556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature selection with RFE\nrfc = RandomForestClassifier()\nrfe = RFE(rfc, n_features_to_select=10)\nrfe.fit(X_train, y_train)\nselected_features = [f for f, s in zip(X_train.columns, rfe.support_) if s]\nX_train = X_train[selected_features]\nX_test = X_test[selected_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:16:19.057627Z","iopub.execute_input":"2024-11-08T07:16:19.058632Z","iopub.status.idle":"2024-11-08T07:24:13.923103Z","shell.execute_reply.started":"2024-11-08T07:16:19.058577Z","shell.execute_reply":"2024-11-08T07:24:13.921815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Define parameter ranges\n# n_estimators_range = [10, 20, 50, 70]\n\n# train_losses = []\n# validation_losses = []\n# train_accuracies = []\n# validation_accuracies = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:24:13.926773Z","iopub.execute_input":"2024-11-08T07:24:13.927185Z","iopub.status.idle":"2024-11-08T07:24:13.932785Z","shell.execute_reply.started":"2024-11-08T07:24:13.927146Z","shell.execute_reply":"2024-11-08T07:24:13.931558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV #cross validation\nimport xgboost as xgb\n\n# xgb_clf = xgb.XGBClassifier(objective='binary:logistic', seed=42, early_stopping_rounds=10, \n#             eval_metric='aucpr')\n\n# xgb_clf.fit(X_train, y_train, verbose=True, eval_set=[(X_test, y_test)])\n\n# Range of n_estimators values to evaluate\nn_estimators_range = range(10, 110, 10)  # 10, 20, ..., 100\n\n# Lists to store training and validation accuracies\ntrain_accuracies = []\nvalidation_accuracies = []\ntrain_losses = []\nvalidation_losses = []\n# Loop through each n_estimators value\nfor n_estimators in n_estimators_range:\n    # Initialize the XGBoost model with current n_estimators\n    xgb_clf = xgb.XGBClassifier(objective='binary:logistic', seed=42, \n                                n_estimators=n_estimators, early_stopping_rounds=10, \n                                eval_metric='aucpr')\n    \n    # Fit the model on training data with validation set for early stopping\n    xgb_clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n\n\n     # Training accuracy\n    y_train_preds = xgb_clf.predict(X_train)\n    train_accuracy = accuracy_score(y_train, y_train_preds)\n    train_accuracies.append(train_accuracy)\n    \n    # Validation accuracy\n    y_test_preds = xgb_clf.predict(X_test)\n    validation_accuracy = accuracy_score(y_test, y_test_preds)\n    validation_accuracies.append(validation_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:24:13.934145Z","iopub.execute_input":"2024-11-08T07:24:13.934507Z","iopub.status.idle":"2024-11-08T07:24:20.152782Z","shell.execute_reply.started":"2024-11-08T07:24:13.934454Z","shell.execute_reply":"2024-11-08T07:24:20.151557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert accuracies to losses (1 - accuracy)\ntrain_losses = [1 - acc for acc in train_accuracies]\nvalidation_losses = [1 - acc for acc in validation_accuracies]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:24:20.154537Z","iopub.execute_input":"2024-11-08T07:24:20.154918Z","iopub.status.idle":"2024-11-08T07:24:20.160401Z","shell.execute_reply.started":"2024-11-08T07:24:20.154879Z","shell.execute_reply":"2024-11-08T07:24:20.159265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Plot the Log Loss Graph\n# plt.figure(figsize=(10, 6))\n# plt.plot(n_estimators_range, train_losses, label='Training Log Loss', marker='o', color='blue')\n# plt.plot(n_estimators_range, validation_losses, label='Validation Log Loss', marker='o', color='orange')\n# plt.xlabel('Number of Trees (n_estimators)')\n# plt.ylabel('Log Loss')\n# plt.title('Training and Validation Log Loss vs. Number of Trees')\n# plt.legend()\n# plt.grid(True)\n# plt.show()\n# Plot the Loss Graph\nplt.figure(figsize=(10, 6))\nplt.plot(n_estimators_range, train_losses, label='Training Loss', marker='o', color='blue')\nplt.plot(n_estimators_range, validation_losses, label='Validation Loss', marker='o', color='orange')\nplt.xlabel('Number of Trees (n_estimators)')\nplt.ylabel('Loss (1 - Accuracy)')\nplt.title('Training and Validation Loss vs. Number of Trees')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:24:20.161945Z","iopub.execute_input":"2024-11-08T07:24:20.162717Z","iopub.status.idle":"2024-11-08T07:24:20.406055Z","shell.execute_reply.started":"2024-11-08T07:24:20.162668Z","shell.execute_reply":"2024-11-08T07:24:20.404874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Plot the Accuracy Graph\n# plt.figure(figsize=(10, 6))\n# plt.plot(n_estimators_range, train_accuracies, label='Training Accuracy', marker='o', color='blue')\n# plt.plot(n_estimators_range, validation_accuracies, label='Validation Accuracy', marker='o', color='orange')\n# plt.xlabel('Number of Trees (n_estimators)')\n# plt.ylabel('Accuracy')\n# plt.title('Training and Validation Accuracy vs. Number of Trees')\n# plt.legend()\n# plt.grid(True)\n# plt.show()\n# Plot the Accuracy Graph\nplt.figure(figsize=(10, 6))\nplt.plot(n_estimators_range, train_accuracies, label='Training Accuracy', marker='o', color='blue')\nplt.plot(n_estimators_range, validation_accuracies, label='Validation Accuracy', marker='o', color='orange')\nplt.xlabel('Number of Trees (n_estimators)')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy vs. Number of Trees')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:24:20.407853Z","iopub.execute_input":"2024-11-08T07:24:20.408262Z","iopub.status.idle":"2024-11-08T07:24:20.660229Z","shell.execute_reply.started":"2024-11-08T07:24:20.408225Z","shell.execute_reply":"2024-11-08T07:24:20.658913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Final model training and evaluation\n# xgb_clf = xgb.XGBClassifier(objective='binary:logistic', n_estimators=500, seed=42, eval_metric='logloss', use_label_encoder=False)\n# xgb_clf.fit(X_train, y_train, verbose=True, eval_set=[(X_test, y_test)], early_stopping_rounds=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:24:20.661635Z","iopub.execute_input":"2024-11-08T07:24:20.661979Z","iopub.status.idle":"2024-11-08T07:24:20.666946Z","shell.execute_reply.started":"2024-11-08T07:24:20.661945Z","shell.execute_reply":"2024-11-08T07:24:20.665750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict and evaluate final model\ny_pred = xgb_clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-08T07:38:37.424792Z","iopub.execute_input":"2024-11-08T07:38:37.425238Z","iopub.status.idle":"2024-11-08T07:38:37.501651Z","shell.execute_reply.started":"2024-11-08T07:38:37.425197Z","shell.execute_reply":"2024-11-08T07:38:37.500542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}