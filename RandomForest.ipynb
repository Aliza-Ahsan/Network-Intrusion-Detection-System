{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120152,"sourceType":"datasetVersion","datasetId":62266}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score \nfrom pandas.api.types import is_numeric_dtype\nimport warnings\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-07T18:30:33.067719Z","iopub.execute_input":"2024-11-07T18:30:33.068172Z","iopub.status.idle":"2024-11-07T18:30:33.082811Z","shell.execute_reply.started":"2024-11-07T18:30:33.068129Z","shell.execute_reply":"2024-11-07T18:30:33.081236Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/network-intrusion-detection/Train_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:38.095963Z","iopub.execute_input":"2024-11-07T18:30:38.096405Z","iopub.status.idle":"2024-11-07T18:30:38.226209Z","shell.execute_reply.started":"2024-11-07T18:30:38.096363Z","shell.execute_reply":"2024-11-07T18:30:38.225146Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\ndef check_constant_columns(train):\n    constant_columns = [col for col in train.columns if train[col].nunique() == 1]\n    return constant_columns\n\n# Example usage\nconstant_cols = check_constant_columns(train)\nif constant_cols:\n    print(f\"Columns with the same value across all rows: {constant_cols}\")\nelse:\n    print(\"No columns have the same value across all rows.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:39.762873Z","iopub.execute_input":"2024-11-07T18:30:39.763711Z","iopub.status.idle":"2024-11-07T18:30:39.807127Z","shell.execute_reply.started":"2024-11-07T18:30:39.763652Z","shell.execute_reply":"2024-11-07T18:30:39.805859Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dropping a column because every value is 0 \ntrain.drop(['num_outbound_cmds'], axis=1, inplace=True)\ntrain.drop(['is_host_login'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:40.879206Z","iopub.execute_input":"2024-11-07T18:30:40.879632Z","iopub.status.idle":"2024-11-07T18:30:40.899132Z","shell.execute_reply.started":"2024-11-07T18:30:40.879593Z","shell.execute_reply":"2024-11-07T18:30:40.898037Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting the Training Dataset into X_train (features) and y_train (label)\nX = train.drop([\"class\"], axis=1)\ny= train[\"class\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:42.007926Z","iopub.execute_input":"2024-11-07T18:30:42.008353Z","iopub.status.idle":"2024-11-07T18:30:42.018038Z","shell.execute_reply.started":"2024-11-07T18:30:42.008316Z","shell.execute_reply":"2024-11-07T18:30:42.016829Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Apply LabelEncoding to all the categorical columns (those with data type 'object')\n\nfrom sklearn.preprocessing import LabelEncoder\n \ndef LabelEncoding(df):\n    for col in df.columns:\n        if df[col].dtype == 'object':\n                label_encoder = LabelEncoder()\n                df[col] = label_encoder.fit_transform(df[col])\n\nLabelEncoding(train)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:43.181826Z","iopub.execute_input":"2024-11-07T18:30:43.182266Z","iopub.status.idle":"2024-11-07T18:30:43.221542Z","shell.execute_reply.started":"2024-11-07T18:30:43.182221Z","shell.execute_reply":"2024-11-07T18:30:43.220438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting the Training Dataset into X_train (features) and y_train (label)\nX = train.drop([\"class\"], axis=1)\ny= train[\"class\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:44.519834Z","iopub.execute_input":"2024-11-07T18:30:44.520269Z","iopub.status.idle":"2024-11-07T18:30:44.533880Z","shell.execute_reply.started":"2024-11-07T18:30:44.520226Z","shell.execute_reply":"2024-11-07T18:30:44.532570Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"{X.shape}\")\nprint(f\"{y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:45.870320Z","iopub.execute_input":"2024-11-07T18:30:45.871097Z","iopub.status.idle":"2024-11-07T18:30:45.876578Z","shell.execute_reply.started":"2024-11-07T18:30:45.871034Z","shell.execute_reply":"2024-11-07T18:30:45.875330Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:47.196723Z","iopub.execute_input":"2024-11-07T18:30:47.197160Z","iopub.status.idle":"2024-11-07T18:30:47.217225Z","shell.execute_reply.started":"2024-11-07T18:30:47.197122Z","shell.execute_reply":"2024-11-07T18:30:47.216136Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score \nnp.random.seed(42)\n\n# #Instantiate Random Forest Classifier\n# clf = RandomForestClassifier(n_estimators=5)\n\n# #Fitting the model to the data \n# clf.fit(X_train, y_train.values.ravel())\n\n# Choose a range of n_estimators to evaluate\n#n_estimators_range = range(1, 101, 10)  # Example: 1, 11, ..., 91\n#Starting estimators from 10\nn_estimators_range = range(10, 110, 10)\n# Arrays to store accuracies\ntrain_accuracies = []\nvalidation_accuracies = []\n\n# Loop through each number of trees\nfor n_estimators in n_estimators_range:\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n    clf.fit(X_train, y_train)\n    \n    # Training accuracy\n    y_train_preds = clf.predict(X_train)\n    train_accuracy = accuracy_score(y_train, y_train_preds)\n    train_accuracies.append(train_accuracy)\n    \n    # Validation accuracy\n    y_test_preds = clf.predict(X_test)\n    validation_accuracy = accuracy_score(y_test, y_test_preds)\n    validation_accuracies.append(validation_accuracy)\n\n# Convert accuracies to \"loss\" (1 - accuracy) to plot\ntrain_losses = [1 - acc for acc in train_accuracies]\nvalidation_losses = [1 - acc for acc in validation_accuracies]","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:30:48.927237Z","iopub.execute_input":"2024-11-07T18:30:48.927698Z","iopub.status.idle":"2024-11-07T18:31:00.586401Z","shell.execute_reply.started":"2024-11-07T18:30:48.927653Z","shell.execute_reply":"2024-11-07T18:31:00.585373Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Calculate the training loss (1 - accuracy)\n# train_pred = clf.predict(X_train)\n# train_accuracy = accuracy_score(y_train, train_pred)\n# train_loss = 1 - accuracy_score(y_train, train_pred)\n# print(f\" train loss: {train_loss * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:31:25.881365Z","iopub.execute_input":"2024-11-07T18:31:25.881789Z","iopub.status.idle":"2024-11-07T18:31:25.886448Z","shell.execute_reply.started":"2024-11-07T18:31:25.881750Z","shell.execute_reply":"2024-11-07T18:31:25.885378Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Calculate the validation loss (1 - accuracy)\n# print(f\"validation loss: {val_loss * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:31:29.754080Z","iopub.execute_input":"2024-11-07T18:31:29.754509Z","iopub.status.idle":"2024-11-07T18:31:29.759537Z","shell.execute_reply.started":"2024-11-07T18:31:29.754454Z","shell.execute_reply":"2024-11-07T18:31:29.758244Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation losses\nplt.figure(figsize=(10, 6))\nplt.plot(n_estimators_range, train_losses, label='Training Loss', marker='o')\nplt.plot(n_estimators_range, validation_losses, label='Validation Loss', marker='o')\nplt.xlabel('Number of Trees (n_estimators)')\nplt.ylabel('Loss (1 - Accuracy)')\nplt.title('Training and Validation Loss vs. Number of Trees')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:31:41.876523Z","iopub.execute_input":"2024-11-07T18:31:41.877223Z","iopub.status.idle":"2024-11-07T18:31:42.275401Z","shell.execute_reply.started":"2024-11-07T18:31:41.877174Z","shell.execute_reply":"2024-11-07T18:31:42.273999Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score \naccuracy = accuracy_score(y_test, y_test_preds)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:32:01.470620Z","iopub.execute_input":"2024-11-07T18:32:01.471439Z","iopub.status.idle":"2024-11-07T18:32:01.479916Z","shell.execute_reply.started":"2024-11-07T18:32:01.471389Z","shell.execute_reply":"2024-11-07T18:32:01.478592Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the training and validation accuracies\nplt.figure(figsize=(12, 6))\nplt.plot(n_estimators_range, train_accuracies, marker='o', color='green', label='Training Accuracy')\nplt.plot(n_estimators_range, validation_accuracies, marker='o', label='Validation Accuracy')\nplt.xlabel(\"Number of Trees (n_estimators)\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy vs. Number of Trees\")\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T18:32:02.535697Z","iopub.execute_input":"2024-11-07T18:32:02.536149Z","iopub.status.idle":"2024-11-07T18:32:02.884443Z","shell.execute_reply.started":"2024-11-07T18:32:02.536106Z","shell.execute_reply":"2024-11-07T18:32:02.883323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Make some prediction\ny_preds= clf.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(classification_report(y_test, y_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T18:32:44.217984Z","iopub.execute_input":"2024-11-07T18:32:44.219095Z","iopub.status.idle":"2024-11-07T18:32:44.304209Z","shell.execute_reply.started":"2024-11-07T18:32:44.219047Z","shell.execute_reply":"2024-11-07T18:32:44.303018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}